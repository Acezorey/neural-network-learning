{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "import matplotlib.pyplot as plt\n",
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import sine_data\n",
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    \n",
    "    # Neuron initialization\n",
    "    def __init__(self, n_inputs, n_neurons, weight_regularizer_l1 = 0, weight_regularizer_l2 = 0, bias_regularizer_l1 = 0, bias_regularizer_l2 = 0):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        # Set regularization strength / Lambda hyperperameters for penalties\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1 \n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2 \n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1 \n",
    "        self.bias_regularizer_l2 = bias_regularizer_l2 \n",
    "\n",
    "    # Neuron forward pass for calculations\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass for derivative backpropagation\n",
    "    def backward(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradients on regularization\n",
    "        # L1 on weights\n",
    "        if self.weight_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.weights)\n",
    "            dL1[self.weights < 0] = -1\n",
    "            self.dweights += self.weight_regularizer_l1 * dL1\n",
    "        # L2 on weights\n",
    "        if self.weight_regularizer_l2 > 0:\n",
    "            self.dweights += 2 * self.weight_regularizer_l2 * self.weights\n",
    "        # L1 on biases\n",
    "        if self.bias_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.biases)\n",
    "            dL1[self.biases < 0] = -1\n",
    "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
    "        # L2 on biases\n",
    "        if self.bias_regularizer_l2 > 0:\n",
    "            self.dbiases += 2 * self.bias_regularizer_l2 * self.biases\n",
    "        \n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectified Linear Unit (ReLU) activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    \n",
    "    # Forward pass for output calculations\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass for derivative backpropagation\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "    \n",
    "    # Forward pass for output\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass for derivative backpropagation\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Sigmoid:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = 1 / (1 + np.exp(-inputs))\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues * (1 - self.output) * self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Linear:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = inputs\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    \n",
    "    # Regularization loss calculation\n",
    "    def regularization_loss(self, layer):\n",
    "        regularization_loss = 0\n",
    "\n",
    "        if layer.weight_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l1 * np.sum(np.abs(layer.weights))\n",
    "        if layer.weight_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l2 * np.sum(layer.weights * layer.weights)\n",
    "\n",
    "        if layer.bias_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l1 * np.sum(np.abs(layer.biases))\n",
    "        if layer.bias_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l2 * np.sum(layer.biases * layer.biases)\n",
    "\n",
    "        return regularization_loss\n",
    "\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategorialCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass for loss calculation output\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis = 1)\n",
    "        \n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "    # Backward pass for derivative backpropagation\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        \n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined softmax activation and cross entropy loss for faster backward step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax_Loss_CategorialCrossentropy():\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategorialCrossentropy()\n",
    "\n",
    "    \n",
    "    def forward(self, inputs, y_true):\n",
    "        self.activation.forward(inputs)\n",
    "        self.output = self.activation.output\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    \n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "        \n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross-Entropy Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_BinaryCrossentropy(Loss):\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        sample_losses = -(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "        sample_losses = np.mean(sample_losses, axis=-1)\n",
    "        return sample_losses\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        outputs = len(dvalues[0])\n",
    "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "        self.dinputs = -(y_true / clipped_dvalues - (1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MeanSquaredError(Loss):\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        sample_losses = np.mean((y_true - y_pred) ** 2, axis = -1)\n",
    "        return sample_losses\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        outputs = len(dvalues[0])\n",
    "        self.dinputs = -2 * (y_true - dvalues) / outputs\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MeanAbsoluteError(Loss):\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        sample_losses = np.mean(np.abs(y_true - y_pred), axis = -1)\n",
    "        return sample_losses\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        outputs = len(dvalues[0])\n",
    "        self.dinputs = np.sign(y_true - dvalues) / outputs\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent with Momentum Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_SGD:\n",
    "\n",
    "    # Gradient descent optimizer initialization\n",
    "    def __init__(self, learning_rate = 1.0, decay = 0, momentum = 0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    # Learning rate decay\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1 + self.decay * self.iterations))\n",
    "\n",
    "\n",
    "    # Parameter updater\n",
    "    def update_params(self, layer):\n",
    "        if self.momentum:\n",
    "\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    \n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adagrad Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_Adagrad:\n",
    "\n",
    "\n",
    "    def __init__(self, learning_rate = 1, decay = 0, epsilon = 1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    \n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1 + self.decay * self.iterations))\n",
    "\n",
    "\n",
    "    def update_params(self, layer):\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weight_cache += layer.dweights ** 2\n",
    "\n",
    "        layer.bias_cache += layer.dbiases ** 2\n",
    "\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    \n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_RMSprop:\n",
    "\n",
    "\n",
    "    def __init__(self, learning_rate = 0.001, decay = 0, epsilon = 1e-7, rho = 0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "\n",
    "\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1 + self.decay * self.iterations))\n",
    "\n",
    "\n",
    "    def update_params(self, layer):\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + (1 - self.rho) * layer.dweights ** 2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + (1 - self.rho) * layer.dbiases ** 2\n",
    "\n",
    "        layer.weights += -self.current_learning_rate *  layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon) \n",
    "        layer.biases += -self.current_learning_rate *  layer.dbiases /  (np.sqrt(layer.bias_cache) + self.epsilon) \n",
    "\n",
    "    \n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam (Adaptive Momentum) Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_Adam:\n",
    "\n",
    "\n",
    "    def __init__(self, learning_rate = 0.001, decay = 0, epsilon = 1e-7, beta_1 = 0.9, beta_2 = 0.999):\n",
    "        self.learning_rate = learning_rate \n",
    "        self.current_learning_rate = learning_rate \n",
    "        self.decay = decay \n",
    "        self.iterations = 0 \n",
    "        self.epsilon = epsilon \n",
    "        self.beta_1 = beta_1 \n",
    "        self.beta_2 = beta_2 \n",
    "\n",
    "\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1 / (1 + self.decay * self.iterations))\n",
    "\n",
    "    \n",
    "    def update_params(self, layer):\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
    "\n",
    "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
    "\n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights ** 2\n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases ** 2\n",
    "\n",
    "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "\n",
    "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
    "\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dropout:\n",
    "    \n",
    "    def __init__(self, rate):\n",
    "        self.rate = 1 - rate\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.binary_mask = np.random.binomial(1, self.rate, size=inputs.shape) / self.rate\n",
    "        self.output = inputs * self.binary_mask\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues * self.binary_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Model Object Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    # Model initializer\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    # Adds layers\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # Sets the loss and optimizer functions and parameters\n",
    "    def set(self, *, loss, optimizer):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    # Trains the model\n",
    "    def train(self, X, y, *, epochs=1, print_every=1):\n",
    "        for epoch in range(1, epochs+1):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.002, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 100, acc: 0.004, loss: 0.164 (data_loss: 0.164, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 200, acc: 0.006, loss: 0.111 (data_loss: 0.111, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 300, acc: 0.005, loss: 0.093 (data_loss: 0.093, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 400, acc: 0.007, loss: 0.073 (data_loss: 0.073, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 500, acc: 0.011, loss: 0.058 (data_loss: 0.058, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 600, acc: 0.082, loss: 0.039 (data_loss: 0.039, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 700, acc: 0.161, loss: 0.020 (data_loss: 0.020, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 800, acc: 0.161, loss: 0.009 (data_loss: 0.009, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 900, acc: 0.236, loss: 0.004 (data_loss: 0.004, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1000, acc: 0.363, loss: 0.002 (data_loss: 0.002, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1100, acc: 0.526, loss: 0.001 (data_loss: 0.001, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1200, acc: 0.553, loss: 0.001 (data_loss: 0.001, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1300, acc: 0.621, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1400, acc: 0.687, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1500, acc: 0.718, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1600, acc: 0.728, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1700, acc: 0.117, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1800, acc: 0.756, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 1900, acc: 0.701, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2000, acc: 0.788, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2100, acc: 0.196, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2200, acc: 0.811, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2300, acc: 0.278, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2400, acc: 0.834, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2500, acc: 0.842, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2600, acc: 0.565, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2700, acc: 0.860, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2800, acc: 0.867, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 2900, acc: 0.872, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3000, acc: 0.883, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3100, acc: 0.526, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3200, acc: 0.897, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3300, acc: 0.907, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3400, acc: 0.914, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3500, acc: 0.919, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3600, acc: 0.815, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3700, acc: 0.940, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3800, acc: 0.945, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 3900, acc: 0.944, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4000, acc: 0.954, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4100, acc: 0.942, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4200, acc: 0.966, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4300, acc: 0.965, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4400, acc: 0.828, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4500, acc: 0.968, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4600, acc: 0.973, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4700, acc: 0.970, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4800, acc: 0.971, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 4900, acc: 0.170, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5000, acc: 0.975, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5100, acc: 0.975, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5200, acc: 0.976, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5300, acc: 0.971, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5400, acc: 0.977, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5500, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5600, acc: 0.975, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5700, acc: 0.979, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5800, acc: 0.126, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 5900, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6000, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6100, acc: 0.980, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6200, acc: 0.980, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6300, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6400, acc: 0.979, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6500, acc: 0.981, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6600, acc: 0.113, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6700, acc: 0.982, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6800, acc: 0.980, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 6900, acc: 0.674, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7000, acc: 0.981, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7100, acc: 0.983, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7200, acc: 0.983, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7300, acc: 0.982, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7400, acc: 0.983, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7500, acc: 0.259, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7600, acc: 0.983, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7700, acc: 0.983, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7800, acc: 0.977, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 7900, acc: 0.984, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8000, acc: 0.976, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8100, acc: 0.984, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8200, acc: 0.984, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8300, acc: 0.960, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8400, acc: 0.983, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8500, acc: 0.984, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8600, acc: 0.980, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8700, acc: 0.985, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8800, acc: 0.988, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 8900, acc: 0.981, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9000, acc: 0.985, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9100, acc: 0.985, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9200, acc: 0.985, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9300, acc: 0.654, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9400, acc: 0.985, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9500, acc: 0.985, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9600, acc: 0.986, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9700, acc: 0.987, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9800, acc: 0.986, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 9900, acc: 0.986, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n",
      "epoch: 10000, acc: 0.982, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001\n"
     ]
    }
   ],
   "source": [
    "X, y = sine_data()\n",
    "\n",
    "dense1 = Layer_Dense(1, 64)\n",
    "\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dense2 = Layer_Dense(64, 64)\n",
    "\n",
    "activation2 = Activation_ReLU()\n",
    "\n",
    "dense3 = Layer_Dense(64, 1)\n",
    "\n",
    "activation3 = Activation_Linear()\n",
    "\n",
    "loss_function = Loss_MeanSquaredError()\n",
    "\n",
    "optimizer = Optimizer_Adam()\n",
    "\n",
    "accuracy_precision = np.std(y) / 250\n",
    "\n",
    "for epoch in range(10001): \n",
    "\n",
    "    dense1.forward(X) \n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    activation2.forward(dense2.output)\n",
    "    dense3.forward(activation2.output)\n",
    "    activation3.forward(dense3.output)\n",
    "\n",
    "    data_loss = loss_function.calculate(activation3.output, y)\n",
    "\n",
    "    regularization_loss = loss_function.regularization_loss(dense1) + loss_function.regularization_loss(dense2) + loss_function.regularization_loss(dense3)\n",
    "\n",
    "    loss = data_loss + regularization_loss\n",
    "\n",
    "    predictions = activation3.output\n",
    "\n",
    "    accuracy = np.mean(np.absolute(predictions - y) < accuracy_precision)\n",
    " \n",
    "    if epoch % 100 == 0: \n",
    "        print(f'epoch: {epoch}, ' + \n",
    "              f'acc: {accuracy:.3f}, ' + \n",
    "              f'loss: {loss:.3f} (' + \n",
    "              f'data_loss: {data_loss:.3f}, ' +\n",
    "              f'reg_loss: {regularization_loss:.3f}), ' + \n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    " \n",
    "    loss_function.backward(activation3.output, y) \n",
    "    activation3.backward(loss_function.dinputs) \n",
    "    dense3.backward(activation3.dinputs) \n",
    "    activation2.backward(dense3.dinputs) \n",
    "    dense2.backward(activation2.dinputs) \n",
    "    activation1.backward(dense2.dinputs) \n",
    "    dense1.backward(activation1.dinputs)  \n",
    "  \n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1) \n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.update_params(dense3)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = sine_data()\n",
    "\n",
    "dense1.forward(X_test) \n",
    "activation1.forward(dense1.output) \n",
    "dense2.forward(activation1.output) \n",
    "activation2.forward(dense2.output) \n",
    "\n",
    "plt.plot(X_test, y_test) \n",
    "plt.plot(X_test, activation3.output) \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
